{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPG/g6R8O9lzKadKzXui+qB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeroTheGreat/Text-to-Video-Synthesis-Colab-/blob/main/TextToVideoSytnhesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qao207UAEx4C"
      },
      "outputs": [],
      "source": [
        "!pip install modelscope==1.4.2\n",
        "!pip install open_clip_torch\n",
        "!pip install pytorch-lightning\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from huggingface_hub import snapshot_download\n",
        "from modelscope.pipelines import pipeline\n",
        "from modelscope.outputs import OutputKeys\n",
        "import pathlib"
      ],
      "metadata": {
        "id": "vozYD5ZUE6Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the models(Models from Modelscope.\n",
        "# They will be uploaded to weights folder.\n",
        "# Reason we are downloading this is to make everything faster if we run the code again.\n",
        "model_dir = pathlib.Path('weights')\n",
        "snapshot_download('damo-vilab/modelscope-damo-text-to-video-synthesis',\n",
        "                   repo_type='model', local_dir=model_dir)\n",
        "\n",
        "# Loading the Pipeline :)\n",
        "pipe = pipeline('text-to-video-synthesis', model_dir.as_posix())"
      ],
      "metadata": {
        "id": "O_LA9jhoEzOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function where we generate the video.\n",
        "def generate_video(text):\n",
        "    try:\n",
        "        test_text = {'text': text}\n",
        "        output_video_path = pipe(test_text)[OutputKeys.OUTPUT_VIDEO]\n",
        "        return output_video_path\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Define The input and output for UI\n",
        "inputs = gr.Textbox(lines=2, label=\"Enter text to generate video\")\n",
        "outputs = gr.Video(label=\"Generated Video\")\n",
        "\n",
        "# Create UI Interface while using Gradio\n",
        "gr.Interface(fn=generate_video, inputs=inputs, outputs=outputs, title=\"Text-to-Video Synthesis\",\n",
        "             description=\"Enter a text to generate a video.\").launch()"
      ],
      "metadata": {
        "id": "IKj7i96UE4Yn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}